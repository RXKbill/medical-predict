{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基于LLM预测化学反应产率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.aliyun.com/pypi/simple/\n",
      "Requirement already satisfied: spark_ai_python in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (0.4.1)\n",
      "Requirement already satisfied: aiohttp>3.3 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from spark_ai_python) (3.9.3)\n",
      "Requirement already satisfied: httpx in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from spark_ai_python) (0.27.0)\n",
      "Requirement already satisfied: jsonpatch in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from spark_ai_python) (1.33)\n",
      "Requirement already satisfied: llama-index<0.11.0,>=0.10.24 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from spark_ai_python) (0.10.56)\n",
      "Requirement already satisfied: llama-index-vector-stores-chroma<0.2.0,>=0.1.6 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from spark_ai_python) (0.1.10)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.6.0 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from spark_ai_python) (1.6.0)\n",
      "Requirement already satisfied: packaging in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from spark_ai_python) (24.0)\n",
      "Requirement already satisfied: pydantic in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from spark_ai_python) (2.8.2)\n",
      "Requirement already satisfied: python-dotenv in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from spark_ai_python) (1.0.1)\n",
      "Requirement already satisfied: pyyaml in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from spark_ai_python) (6.0.1)\n",
      "Requirement already satisfied: requests in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from spark_ai_python) (2.32.3)\n",
      "Requirement already satisfied: tenacity in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from spark_ai_python) (8.5.0)\n",
      "Requirement already satisfied: websocket-client<2.0.0,>=1.7.0 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from spark_ai_python) (1.8.0)\n",
      "Requirement already satisfied: websockets in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from spark_ai_python) (12.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from aiohttp>3.3->spark_ai_python) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from aiohttp>3.3->spark_ai_python) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from aiohttp>3.3->spark_ai_python) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from aiohttp>3.3->spark_ai_python) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from aiohttp>3.3->spark_ai_python) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from aiohttp>3.3->spark_ai_python) (4.0.3)\n",
      "Requirement already satisfied: llama-index-agent-openai<0.3.0,>=0.1.4 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from llama-index<0.11.0,>=0.10.24->spark_ai_python) (0.2.9)\n",
      "Requirement already satisfied: llama-index-cli<0.2.0,>=0.1.2 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from llama-index<0.11.0,>=0.10.24->spark_ai_python) (0.1.12)\n",
      "Requirement already satisfied: llama-index-core==0.10.56 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from llama-index<0.11.0,>=0.10.24->spark_ai_python) (0.10.56)\n",
      "Requirement already satisfied: llama-index-embeddings-openai<0.2.0,>=0.1.5 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from llama-index<0.11.0,>=0.10.24->spark_ai_python) (0.1.11)\n",
      "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.2.0 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from llama-index<0.11.0,>=0.10.24->spark_ai_python) (0.2.5)\n",
      "Requirement already satisfied: llama-index-legacy<0.10.0,>=0.9.48 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from llama-index<0.11.0,>=0.10.24->spark_ai_python) (0.9.48)\n",
      "Requirement already satisfied: llama-index-llms-openai<0.2.0,>=0.1.13 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from llama-index<0.11.0,>=0.10.24->spark_ai_python) (0.1.26)\n",
      "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from llama-index<0.11.0,>=0.10.24->spark_ai_python) (0.1.8)\n",
      "Requirement already satisfied: llama-index-program-openai<0.2.0,>=0.1.3 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from llama-index<0.11.0,>=0.10.24->spark_ai_python) (0.1.6)\n",
      "Requirement already satisfied: llama-index-question-gen-openai<0.2.0,>=0.1.2 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from llama-index<0.11.0,>=0.10.24->spark_ai_python) (0.1.3)\n",
      "Requirement already satisfied: llama-index-readers-file<0.2.0,>=0.1.4 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from llama-index<0.11.0,>=0.10.24->spark_ai_python) (0.1.30)\n",
      "Requirement already satisfied: llama-index-readers-llama-parse>=0.1.2 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from llama-index<0.11.0,>=0.10.24->spark_ai_python) (0.1.6)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core==0.10.56->llama-index<0.11.0,>=0.10.24->spark_ai_python) (2.0.31)\n",
      "Requirement already satisfied: dataclasses-json in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from llama-index-core==0.10.56->llama-index<0.11.0,>=0.10.24->spark_ai_python) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from llama-index-core==0.10.56->llama-index<0.11.0,>=0.10.24->spark_ai_python) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from llama-index-core==0.10.56->llama-index<0.11.0,>=0.10.24->spark_ai_python) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from llama-index-core==0.10.56->llama-index<0.11.0,>=0.10.24->spark_ai_python) (2024.3.1)\n",
      "Requirement already satisfied: networkx>=3.0 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from llama-index-core==0.10.56->llama-index<0.11.0,>=0.10.24->spark_ai_python) (3.1)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from llama-index-core==0.10.56->llama-index<0.11.0,>=0.10.24->spark_ai_python) (3.8.1)\n",
      "Requirement already satisfied: numpy<2.0.0 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from llama-index-core==0.10.56->llama-index<0.11.0,>=0.10.24->spark_ai_python) (1.24.4)\n",
      "Requirement already satisfied: openai>=1.1.0 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from llama-index-core==0.10.56->llama-index<0.11.0,>=0.10.24->spark_ai_python) (1.35.3)\n",
      "Requirement already satisfied: pandas in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from llama-index-core==0.10.56->llama-index<0.11.0,>=0.10.24->spark_ai_python) (2.0.3)\n",
      "Requirement already satisfied: pillow>=9.0.0 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from llama-index-core==0.10.56->llama-index<0.11.0,>=0.10.24->spark_ai_python) (10.3.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from llama-index-core==0.10.56->llama-index<0.11.0,>=0.10.24->spark_ai_python) (0.7.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from llama-index-core==0.10.56->llama-index<0.11.0,>=0.10.24->spark_ai_python) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from llama-index-core==0.10.56->llama-index<0.11.0,>=0.10.24->spark_ai_python) (4.11.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from llama-index-core==0.10.56->llama-index<0.11.0,>=0.10.24->spark_ai_python) (0.9.0)\n",
      "Requirement already satisfied: wrapt in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from llama-index-core==0.10.56->llama-index<0.11.0,>=0.10.24->spark_ai_python) (1.16.0)\n",
      "Requirement already satisfied: chromadb<0.6.0,>=0.4.0 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python) (0.5.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from requests->spark_ai_python) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from requests->spark_ai_python) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from requests->spark_ai_python) (1.26.19)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from requests->spark_ai_python) (2024.2.2)\n",
      "Requirement already satisfied: anyio in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from httpx->spark_ai_python) (3.7.1)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from httpx->spark_ai_python) (1.0.5)\n",
      "Requirement already satisfied: sniffio in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from httpx->spark_ai_python) (1.2.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from httpcore==1.*->httpx->spark_ai_python) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from jsonpatch->spark_ai_python) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from pydantic->spark_ai_python) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from pydantic->spark_ai_python) (2.20.1)\n",
      "Requirement already satisfied: build>=1.0.3 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python) (1.2.1)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.5 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python) (0.7.5)\n",
      "Requirement already satisfied: fastapi>=0.95.2 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python) (0.111.1)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python) (0.30.2)\n",
      "Requirement already satisfied: posthog>=2.4.0 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python) (3.5.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python) (1.18.1)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python) (1.25.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python) (1.25.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python) (0.46b0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python) (1.25.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python) (0.19.1)\n",
      "Requirement already satisfied: pypika>=0.48.9 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python) (0.48.9)\n",
      "Requirement already satisfied: overrides>=7.3.1 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python) (6.4.0)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python) (1.62.1)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python) (4.1.3)\n",
      "Requirement already satisfied: typer>=0.9.0 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python) (0.12.3)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python) (30.1.0)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python) (4.1.0)\n",
      "Requirement already satisfied: orjson>=3.9.12 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python) (3.10.6)\n",
      "Requirement already satisfied: graphlib-backport>=1.0.3 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python) (1.1.0)\n",
      "Requirement already satisfied: llama-cloud>=0.0.9 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from llama-index-indices-managed-llama-cloud>=0.2.0->llama-index<0.11.0,>=0.10.24->spark_ai_python) (0.0.9)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index<0.11.0,>=0.10.24->spark_ai_python) (4.12.3)\n",
      "Requirement already satisfied: pypdf<5.0.0,>=4.0.1 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index<0.11.0,>=0.10.24->spark_ai_python) (4.3.0)\n",
      "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index<0.11.0,>=0.10.24->spark_ai_python) (0.0.26)\n",
      "Requirement already satisfied: llama-parse>=0.4.0 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from llama-index-readers-llama-parse>=0.1.2->llama-index<0.11.0,>=0.10.24->spark_ai_python) (0.4.9)\n",
      "Requirement already satisfied: exceptiongroup in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from anyio->httpx->spark_ai_python) (1.2.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.2.0,>=0.1.4->llama-index<0.11.0,>=0.10.24->spark_ai_python) (2.5)\n",
      "Requirement already satisfied: pyproject_hooks in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from build>=1.0.3->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python) (1.1.0)\n",
      "Requirement already satisfied: colorama in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from build>=1.0.3->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python) (0.4.6)\n",
      "Requirement already satisfied: importlib-metadata>=4.6 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from build>=1.0.3->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python) (7.1.0)\n",
      "Requirement already satisfied: tomli>=1.1.0 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from build>=1.0.3->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python) (1.2.2)\n",
      "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from fastapi>=0.95.2->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python) (0.37.2)\n",
      "Requirement already satisfied: fastapi-cli>=0.0.2 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from fastapi>=0.95.2->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python) (0.0.4)\n",
      "Requirement already satisfied: jinja2>=2.11.2 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from fastapi>=0.95.2->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python) (3.1.3)\n",
      "Requirement already satisfied: python-multipart>=0.0.7 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from fastapi>=0.95.2->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python) (0.0.9)\n",
      "Requirement already satisfied: email_validator>=2.0.0 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from fastapi>=0.95.2->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python) (2.2.0)\n",
      "Requirement already satisfied: six>=1.9.0 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python) (2.9.0.post0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python) (2.29.0)\n",
      "Requirement already satisfied: requests-oauthlib in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python) (3.2.2)\n",
      "Requirement already satisfied: click in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core==0.10.56->llama-index<0.11.0,>=0.10.24->spark_ai_python) (8.1.7)\n",
      "Requirement already satisfied: joblib in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core==0.10.56->llama-index<0.11.0,>=0.10.24->spark_ai_python) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core==0.10.56->llama-index<0.11.0,>=0.10.24->spark_ai_python) (2024.5.15)\n",
      "Requirement already satisfied: coloredlogs in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python) (24.3.25)\n",
      "Requirement already satisfied: protobuf in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python) (4.25.3)\n",
      "Requirement already satisfied: sympy in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python) (1.12)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from openai>=1.1.0->llama-index-core==0.10.56->llama-index<0.11.0,>=0.10.24->spark_ai_python) (1.9.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python) (1.63.2)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.25.0 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python) (1.25.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.25.0 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python) (1.25.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.46b0 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python) (0.46b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.46b0 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python) (0.46b0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.46b0 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python) (0.46b0)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.46b0 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python) (0.46b0)\n",
      "Requirement already satisfied: setuptools>=16.0 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from opentelemetry-instrumentation==0.46b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python) (68.2.2)\n",
      "Requirement already satisfied: asgiref~=3.0 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from opentelemetry-instrumentation-asgi==0.46b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python) (3.8.1)\n",
      "Requirement already satisfied: monotonic>=1.5 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from posthog>=2.4.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from posthog>=2.4.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python) (2.2.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core==0.10.56->llama-index<0.11.0,>=0.10.24->spark_ai_python) (3.0.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from tokenizers>=0.13.2->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python) (0.24.0)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from typer>=0.9.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from typer>=0.9.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python) (13.7.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core==0.10.56->llama-index<0.11.0,>=0.10.24->spark_ai_python) (1.0.0)\n",
      "Requirement already satisfied: httptools>=0.5.0 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python) (0.6.1)\n",
      "Requirement already satisfied: watchfiles>=0.13 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python) (0.22.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from dataclasses-json->llama-index-core==0.10.56->llama-index<0.11.0,>=0.10.24->spark_ai_python) (3.21.3)\n",
      "Requirement already satisfied: zipp>=3.1.0 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from importlib-resources->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python) (3.6.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from pandas->llama-index-core==0.10.56->llama-index<0.11.0,>=0.10.24->spark_ai_python) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from pandas->llama-index-core==0.10.56->llama-index<0.11.0,>=0.10.24->spark_ai_python) (2024.1)\n",
      "Requirement already satisfied: dnspython>=2.0.0 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from email_validator>=2.0.0->fastapi>=0.95.2->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python) (2.6.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python) (4.9)\n",
      "Requirement already satisfied: filelock in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python) (3.11.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from jinja2>=2.11.2->fastapi>=0.95.2->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from rich>=10.11.0->typer>=0.9.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from rich>=10.11.0->typer>=0.9.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python) (2.17.2)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python) (10.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python) (1.3.0)\n",
      "Requirement already satisfied: pyreadline3 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python) (3.4.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.9.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python) (0.1.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in d:\\anaconda3\\envs\\ddm\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python) (0.6.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install spark_ai_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\ddm\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm.auto import tqdm\n",
    "import logging\n",
    "import time\n",
    "import concurrent.futures\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'您好，我是讯飞星火认知大模型，由科大讯飞构建的认知智能大模型。\\n我设计用于与人类进行自然语言交流，旨在解答各种问题和提供帮助，覆盖广泛的领域知识。通过深度学习和大数据分析，我能够理解和处理复杂的查询，从而高效地满足用户在教育、医疗、金融等多个行业的认知智能需求。'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sparkai.llm.llm import ChatSparkLLM, ChunkPrintHandler\n",
    "from sparkai.core.messages import ChatMessage\n",
    "\n",
    "#星火认知大模型Spark3.5 Max的URL值，其他版本大模型URL值请前往文档（https://www.xfyun.cn/doc/spark/Web.html）查看\n",
    "SPARKAI_URL = 'wss://spark-api.xf-yun.com/v3.5/chat'\n",
    "#星火认知大模型调用秘钥信息，请前往讯飞开放平台控制台（https://console.xfyun.cn/services/bm35）查看\n",
    "SPARKAI_APP_ID=\"xxxx\"\n",
    "SPARKAI_API_SECRET=\"xxxx\"\n",
    "SPARKAI_API_KEY=\"xxxx\"\n",
    "#星火认知大模型Spark3.5 Max的domain值，其他版本大模型domain值请前往文档（https://www.xfyun.cn/doc/spark/Web.html）查看\n",
    "SPARKAI_DOMAIN = 'generalv3.5'\n",
    "\n",
    "def get_completions(text):\n",
    "    messages = [ChatMessage(\n",
    "        role=\"user\",\n",
    "        content=text\n",
    "    )]\n",
    "    spark = ChatSparkLLM(\n",
    "        spark_api_url=SPARKAI_URL,\n",
    "        spark_app_id=SPARKAI_APP_ID,\n",
    "        spark_api_key=SPARKAI_API_KEY,\n",
    "        spark_api_secret=SPARKAI_API_SECRET,\n",
    "        spark_llm_domain=SPARKAI_DOMAIN,\n",
    "        streaming=False,\n",
    "    )\n",
    "    handler = ChunkPrintHandler()\n",
    "    a = spark.generate([messages], callbacks=[handler])\n",
    "    return a.generations[0][0].text\n",
    "\n",
    "# 测试模型配置是否正确\n",
    "text = \"你是谁\"\n",
    "get_completions(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建Prompt模板\n",
    "chem_prompt = \"\"\"\n",
    "你精通预测药物合成反应的产率，你的任务是根据给定的反应数据准确预测反应的产率(Yield)。请仔细阅读以下说明并严格遵循:\n",
    "\n",
    "***** 任务描述：*****\n",
    "1. 你将获得一个相应物质的SMILES字符串字段组成的催化合成反应数据，包含Reactant1(反应物1)、Reactant2(反应物2)、Product(产物)、Additive(添加剂)、Solvent(溶剂)。\n",
    "2. 数据为药物合成中常用的碳氮键形成反应。\n",
    "3. 待预测的Yield是目标字段是归一化为0到1之间的4位浮点数，表示反应的产率。\n",
    "\n",
    "***** 你的任务：*****\n",
    "1. 仔细分析提供的示例数据，理解反应与Yield之间的关系。\n",
    "2. 根据待预测样本的数据，预测其反应产率Yield。\n",
    "3. 输出预测的Yield值，精确到小数点后四位。\n",
    "\n",
    "***** 输出格式要求：*****\n",
    "1. 仅输出预测的Yield值，不要包含任何其他解释或评论。\n",
    "2. 使用以下格式输出你的预测：@{{预测的Yield值}}\n",
    "   例如：@{{0.7823}}\n",
    "\n",
    "***** 注意事项：*****\n",
    "1. 即使你是一个人工智能模型，但是你有能力直接预测反应的产率，请你一定输出预测的产率，不要回避这个问题。\n",
    "2. 相似SMILES的反应产率可能也会有很大差异。\n",
    "2. 你确保你的预测是合理的，介于0.0000到1.0000之间。\n",
    "2. 不要遗漏小数点后的零，始终保持四位小数的格式。\n",
    "3. 不要在输出中包含任何额外的空格或换行符。\n",
    "\n",
    "以下是几个示例数据，供你参考：\n",
    "\n",
    "***** 示例样本 *****\n",
    "{examples}\n",
    "\n",
    "现在，请基于以上示例和说明，预测以下反应的产率：\n",
    "\n",
    "**** 待预测样本 ****\n",
    "Reactant1: {test_reactant1}  \n",
    "Reactant2: {test_reactant2}  \n",
    "Product: {test_product}  \n",
    "Additive: {test_additive} \n",
    "Solvent: {test_solvent}  \n",
    "Yield: @{{}}\n",
    "\n",
    "请仅输出产率预测值，格式如下：\n",
    "@{{预测的Yield值}}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(prompt_template, test_sample, top_5_samples):\n",
    "    examples = \"\\n\\n\".join([\n",
    "        # f\"rxnid: {row['rxnid']}  \\n\"\n",
    "        f\"Reactant1: {row['Reactant1']}  \\n\"\n",
    "        f\"Reactant2: {row['Reactant2']}  \\n\"\n",
    "        f\"Product: {row['Product']}  \\n\"\n",
    "        f\"Additive: {row['Additive']}  \\n\"\n",
    "        f\"Solvent: {row['Solvent']}  \\n\"\n",
    "        f\"Yield: {row['Yield']}\"\n",
    "        for _, row in top_5_samples.iterrows()\n",
    "    ])\n",
    "    \n",
    "    return prompt_template.format(\n",
    "        examples=examples,\n",
    "        # test_rxnid=test_sample['rxnid'],\n",
    "        test_reactant1=test_sample['Reactant1'],\n",
    "        test_reactant2=test_sample['Reactant2'],\n",
    "        test_product=test_sample['Product'],\n",
    "        test_additive=test_sample['Additive'],\n",
    "        test_solvent=test_sample['Solvent']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置日志\n",
    "import backoff\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# 使用 backoff 装饰器来处理 API 调用的重试\n",
    "@backoff.on_exception(backoff.expo,\n",
    "                      Exception,\n",
    "                      max_tries=5,\n",
    "                      max_time=300)\n",
    "\n",
    "# 处理单个样本\n",
    "def process_single_sample(args):\n",
    "    test_sample, train_df, train_tfidf, tfidf = args\n",
    "    try:\n",
    "        test_tfidf = tfidf.transform([test_sample['combined_features']])\n",
    "        similarities = cosine_similarity(test_tfidf, train_tfidf).flatten()\n",
    "        top_k_indices = similarities.argsort()[-3:][::-1]\n",
    "        top_k_samples = train_df.iloc[top_k_indices]\n",
    "        prompt = generate_prompt(chem_prompt, test_sample, top_k_samples)\n",
    "        # print(prompt)\n",
    "        prediction = get_completions(prompt)\n",
    "        # print(prediction)\n",
    "        yield_value = extract_yield(prediction)\n",
    "        # print(yield_value)\n",
    "        if yield_value is None:\n",
    "            raise ValueError(f\"无法从预测结果中提取有效的产率值\")\n",
    "        return test_sample['rxnid'], yield_value, None\n",
    "    except Exception as e:\n",
    "        return test_sample['rxnid'], None, str(e)\n",
    "\n",
    "def extract_yield(prediction):\n",
    "    yield_match = re.search(r'@{(.+?)}', prediction)\n",
    "    if yield_match:\n",
    "        yield_value = yield_match.group(1)\n",
    "        try:\n",
    "            float_yield = float(yield_value)\n",
    "            if 0 <= float_yield <= 1:\n",
    "                return f\"{float_yield:.4f}\"\n",
    "            else:\n",
    "                logger.warning(f\"提取的产率值 {float_yield} 不在有效范围内\")\n",
    "        except ValueError:\n",
    "            logger.warning(f\"无法将提取的值 '{yield_value}' 转换为浮点数\")\n",
    "    else:\n",
    "        logger.warning(f\"无法从预测结果中提取产率值。\") # 完整响应：{prediction}\n",
    "    return None\n",
    "\n",
    "# 并行处理样本\n",
    "def process_samples_parallel(test_df, train_df, train_tfidf, tfidf, max_workers=None, batch_size=100):\n",
    "    results = {}\n",
    "    error_indices = []\n",
    "    total_samples = len(test_df)\n",
    "\n",
    "    logger.info(f\"开始并行处理 {total_samples} 个测试样本\")\n",
    "\n",
    "    # 如果没有指定max_workers，API最大支持2的并行\n",
    "    if max_workers is None:\n",
    "        max_workers = 2\n",
    "\n",
    "    # 将数据分成批次\n",
    "    batches = [test_df[i:i+batch_size] for i in range(0, total_samples, batch_size)]\n",
    "\n",
    "    with tqdm(total=total_samples, desc=\"处理测试样本\", unit=\"sample\") as pbar:\n",
    "        for batch in batches:\n",
    "            with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "                futures = [executor.submit(process_single_sample, (row, train_df, train_tfidf, tfidf)) \n",
    "                           for _, row in batch.iterrows()]\n",
    "                \n",
    "                for future in concurrent.futures.as_completed(futures):\n",
    "                    rxnid, yield_value, error = future.result()\n",
    "                    if error:\n",
    "                        logger.error(f\"处理样本 {rxnid} 时出错: {error}\")\n",
    "                        error_indices.append(rxnid)\n",
    "                    else:\n",
    "                        results[rxnid] = yield_value\n",
    "                    pbar.update(1)\n",
    "                    \n",
    "                    # 更新预计完成时间\n",
    "                    elapsed_time = pbar.format_dict['elapsed']\n",
    "                    rate = pbar.format_dict['rate']\n",
    "                    if rate and rate > 0:\n",
    "                        remaining_time = (total_samples - pbar.n) / rate\n",
    "                        eta = time.strftime(\"%H:%M:%S\", time.gmtime(remaining_time))\n",
    "                        pbar.set_postfix({'ETA': eta}, refresh=True)\n",
    "\n",
    "    return results, error_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-24 15:02:22,815 - INFO - 开始读取数据...\n",
      "2024-07-24 15:02:22,879 - INFO - 训练集产率平均值: 0.6299\n",
      "2024-07-24 15:02:22,901 - INFO - 数据读取完成\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集数据预览：\n",
      "    rxnid               Reactant1        Reactant2  \\\n",
      "0  train1  c1ccc2c(c1)Nc1ccccc1O2      Brc1ccccc1I   \n",
      "1  train2  c1ccc2c(c1)Nc1ccccc1O2      Brc1ccccc1I   \n",
      "2  train3  c1ccc2c(c1)Nc1ccccc1O2      Brc1ccccc1I   \n",
      "3  train4                C1COCCN1  Fc1cnc(Cl)nc1Cl   \n",
      "4  train5                C1COCCN1  Fc1cnc(Cl)nc1Cl   \n",
      "\n",
      "                          Product  \\\n",
      "0  Brc1ccccc1N1c2ccccc2Oc2ccccc21   \n",
      "1  Brc1ccccc1N1c2ccccc2Oc2ccccc21   \n",
      "2  Brc1ccccc1N1c2ccccc2Oc2ccccc21   \n",
      "3           Fc1cnc(Cl)nc1N1CCOCC1   \n",
      "4           Fc1cnc(Cl)nc1N1CCOCC1   \n",
      "\n",
      "                                            Additive         Solvent   Yield  \n",
      "0  CC(C)(C)[O-].CC(C)(C)[PH+](C(C)(C)C)C(C)(C)C.F...       Cc1ccccc1  0.7800  \n",
      "1  C1COCCOCCOCCOCCOCCO1.O=C([O-])[O-].[Cu+].[I-]....    Clc1ccccc1Cl  0.9000  \n",
      "2  CC(=O)[O-].CC(=O)[O-].CC(C)(C)[O-].CC(C)(C)[PH...  CC1(C)C=CC=CC1  0.8464  \n",
      "3                                    CCN(C(C)C)C(C)C             CCO  0.9500  \n",
      "4                                    CCN(C(C)C)C(C)C        CN(C)C=O  0.8500  \n",
      "\n",
      "测试集数据预览：\n",
      "   rxnid                           Reactant1  \\\n",
      "0  test1                    COC(=O)C1(C)CNC1   \n",
      "1  test2                    c1cc2cc[nH]c2cn1   \n",
      "2  test3                      CN(C)C1CCCNCC1   \n",
      "3  test4  CC1(C)CC(=O)c2c(C(F)(F)F)c[nH]c2C1   \n",
      "4  test5                         O=C1CCNCCN1   \n",
      "\n",
      "                                Reactant2  \\\n",
      "0                         Fc1cnc(Cl)nc1Cl   \n",
      "1                           Clc1ccc(I)cc1   \n",
      "2                             Fc1ccncc1Br   \n",
      "3  N#Cc1c(F)cc(Br)cc1N[C@H]1CC[C@H](O)CC1   \n",
      "4                     FC(F)(F)c1cccc(I)c1   \n",
      "\n",
      "                                             Product  \\\n",
      "0                    COC(=O)C1(C)CN(c2nc(Cl)ncc2F)C1   \n",
      "1                         Clc1ccc(-n2ccc3ccncc32)cc1   \n",
      "2                         CN(C)C1CCCN(c2ccncc2Br)CC1   \n",
      "3  CC1(C)CC(=O)c2c(C(F)(F)F)cn(-c3cc(F)c(C#N)c(NC...   \n",
      "4                    O=C1CCN(c2cccc(C(F)(F)F)c2)CCN1   \n",
      "\n",
      "                                            Additive             Solvent  \n",
      "0                                          CCN(CC)CC              CC(C)O  \n",
      "1  CNCCNC.O=P([O-])([O-])[O-].[Cu+2].[I-].[I-].[K...            CN(C)C=O  \n",
      "2                                    CCN(C(C)C)C(C)C         CC(=O)N(C)C  \n",
      "3    CNCCNC.O=C([O-])[O-].[Cu+2].[I-].[I-].[K+].[K+]   C1COCCO1.C1COCCO1  \n",
      "4                          O=C([O-])[O-].[Cs+].[Cs+]  C1COCCO1.Cc1ccccc1  \n",
      "\n",
      "训练集基本信息：\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23538 entries, 0 to 23537\n",
      "Data columns (total 7 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   rxnid      23538 non-null  object\n",
      " 1   Reactant1  23538 non-null  object\n",
      " 2   Reactant2  23538 non-null  object\n",
      " 3   Product    23538 non-null  object\n",
      " 4   Additive   23538 non-null  object\n",
      " 5   Solvent    23538 non-null  object\n",
      " 6   Yield      23538 non-null  object\n",
      "dtypes: object(7)\n",
      "memory usage: 1.3+ MB\n",
      "None\n",
      "\n",
      "测试集基本信息：\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2616 entries, 0 to 2615\n",
      "Data columns (total 6 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   rxnid      2616 non-null   object\n",
      " 1   Reactant1  2616 non-null   object\n",
      " 2   Reactant2  2616 non-null   object\n",
      " 3   Product    2616 non-null   object\n",
      " 4   Additive   2616 non-null   object\n",
      " 5   Solvent    2616 non-null   object\n",
      "dtypes: object(6)\n",
      "memory usage: 122.8+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"开始读取数据...\")\n",
    "train_df = pd.read_csv('round1_train_data.csv')\n",
    "\n",
    "# 计算训练集的产率平均值\n",
    "train_yield_mean = train_df['Yield'].mean()\n",
    "logger.info(f\"训练集产率平均值: {train_yield_mean:.4f}\")\n",
    "\n",
    "train_df['Yield'] = train_df['Yield'].apply(lambda x: f\"{float(x):.4f}\")\n",
    "test_df = pd.read_csv('round1_test_data.csv')\n",
    "logger.info(\"数据读取完成\")\n",
    "\n",
    "\n",
    "# 显示训练集的前几行\n",
    "print(\"训练集数据预览：\")\n",
    "print(train_df.head())\n",
    "\n",
    "# 显示测试集的前几行\n",
    "print(\"\\n测试集数据预览：\")\n",
    "print(test_df.head())\n",
    "\n",
    "# 显示训练集的基本信息\n",
    "print(\"\\n训练集基本信息：\")\n",
    "print(train_df.info())\n",
    "\n",
    "# 显示测试集的基本信息\n",
    "print(\"\\n测试集基本信息：\")\n",
    "print(test_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-24 15:02:22,942 - INFO - 开始特征提取...\n",
      "2024-07-24 15:02:23,683 - INFO - 特征提取完成\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"开始特征提取...\")\n",
    "\n",
    "# 创建TF-IDF向量化器\n",
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "# 将所有文本特征组合成一个字符串\n",
    "def combine_features(row):\n",
    "    return ' '.join([str(row['Reactant1']), str(row['Reactant2']), str(row['Product']), str(row['Additive']), str(row['Solvent'])])\n",
    "\n",
    "train_df['combined_features'] = train_df.apply(combine_features, axis=1)\n",
    "test_df['combined_features'] = test_df.apply(combine_features, axis=1)\n",
    "train_tfidf = tfidf.fit_transform(train_df['combined_features'])\n",
    "\n",
    "logger.info(\"特征提取完成\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-24 15:02:31,518 - INFO - 开始并行处理测试样本...\n",
      "2024-07-24 15:02:31,519 - INFO - 开始并行处理 20 个测试样本\n",
      "处理测试样本:   0%|          | 0/20 [00:00<?, ?sample/s]2024-07-24 15:02:31,629 - INFO - Websocket connected\n",
      "2024-07-24 15:02:31,643 - INFO - Websocket connected\n",
      "处理测试样本:   5%|▌         | 1/20 [00:02<00:42,  2.23s/sample, ETA=00:00:42]2024-07-24 15:02:33,848 - INFO - Websocket connected\n",
      "处理测试样本:  10%|█         | 2/20 [00:02<00:19,  1.11s/sample, ETA=00:00:19]2024-07-24 15:02:34,159 - INFO - Websocket connected\n",
      "处理测试样本:  15%|█▌        | 3/20 [00:04<00:25,  1.52s/sample, ETA=00:00:25]2024-07-24 15:02:36,258 - INFO - Websocket connected\n",
      "处理测试样本:  20%|██        | 4/20 [00:05<00:20,  1.28s/sample, ETA=00:00:20]2024-07-24 15:02:37,088 - INFO - Websocket connected\n",
      "处理测试样本:  25%|██▌       | 5/20 [00:06<00:20,  1.35s/sample, ETA=00:00:20]2024-07-24 15:02:38,558 - INFO - Websocket connected\n",
      "处理测试样本:  30%|███       | 6/20 [00:07<00:17,  1.22s/sample, ETA=00:00:17]2024-07-24 15:02:39,523 - INFO - Websocket connected\n",
      "处理测试样本:  35%|███▌      | 7/20 [00:09<00:16,  1.27s/sample, ETA=00:00:16]2024-07-24 15:02:40,907 - INFO - Websocket connected\n",
      "处理测试样本:  40%|████      | 8/20 [00:10<00:15,  1.27s/sample, ETA=00:00:15]2024-07-24 15:02:42,177 - INFO - Websocket connected\n",
      "处理测试样本:  45%|████▌     | 9/20 [00:11<00:11,  1.07s/sample, ETA=00:00:11]2024-07-24 15:02:42,804 - INFO - Websocket connected\n",
      "处理测试样本:  50%|█████     | 10/20 [00:13<00:14,  1.42s/sample, ETA=00:00:14]2024-07-24 15:02:45,052 - INFO - Websocket connected\n",
      "处理测试样本:  55%|█████▌    | 11/20 [00:13<00:09,  1.04s/sample, ETA=00:00:09]2024-07-24 15:02:45,170 - INFO - Websocket connected\n",
      "处理测试样本:  60%|██████    | 12/20 [00:15<00:10,  1.34s/sample, ETA=00:00:10]2024-07-24 15:02:47,196 - INFO - Websocket connected\n",
      "处理测试样本:  65%|██████▌   | 13/20 [00:15<00:06,  1.01sample/s, ETA=00:00:06]2024-07-24 15:02:47,381 - INFO - Websocket connected\n",
      "处理测试样本:  70%|███████   | 14/20 [00:18<00:08,  1.36s/sample, ETA=00:00:08]2024-07-24 15:02:49,604 - INFO - Websocket connected\n",
      "处理测试样本:  75%|███████▌  | 15/20 [00:18<00:04,  1.01sample/s, ETA=00:00:04]2024-07-24 15:02:49,729 - INFO - Websocket connected\n",
      "处理测试样本:  80%|████████  | 16/20 [00:21<00:06,  1.59s/sample, ETA=00:00:06]2024-07-24 15:02:52,723 - INFO - Websocket connected\n",
      "处理测试样本:  85%|████████▌ | 17/20 [00:22<00:04,  1.50s/sample, ETA=00:00:04]2024-07-24 15:02:54,011 - INFO - Websocket connected\n",
      "处理测试样本:  90%|█████████ | 18/20 [00:23<00:02,  1.37s/sample, ETA=00:00:02]2024-07-24 15:02:55,083 - INFO - Websocket connected\n",
      "处理测试样本: 100%|██████████| 20/20 [00:25<00:00,  1.29s/sample, ETA=00:00:00]\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"开始并行处理测试样本...\")\n",
    "results, error_indices = process_samples_parallel(test_df, train_df, train_tfidf, tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理测试样本: 100%|██████████| 2616/2616 [00:23<00:00, 110.40it/s]\n"
     ]
    }
   ],
   "source": [
    "# 利用相似样本的均值填补大模型无法预测的空缺值\n",
    "\n",
    "default_yield = []\n",
    "\n",
    "for index, test_sample in tqdm(test_df.iterrows(), total=len(test_df), desc=\"处理测试样本\"):\n",
    "        # 对测试样本进行TF-IDF转换\n",
    "        test_tfidf = tfidf.transform([test_sample['combined_features']])\n",
    "        \n",
    "        # 计算与训练集的相似度\n",
    "        similarities = cosine_similarity(test_tfidf, train_tfidf).flatten()\n",
    "        \n",
    "        # 获取最相似的5个样本的索引\n",
    "        top_k_indices = similarities.argsort()[-3:][::-1]\n",
    "    \n",
    "        # 获取最相似的5个样本的产率\n",
    "        top_k_yields = train_df.iloc[top_k_indices]['Yield'].astype(float).values\n",
    "        \n",
    "        # 获取相似度权重\n",
    "        weights = similarities[top_k_indices]\n",
    "        # 对权重进行归一化\n",
    "        weights = weights / weights.sum()\n",
    "        \n",
    "        # 计算这五个samples的产率加权平均\n",
    "        weighted_yield = np.dot(top_k_yields, weights) \n",
    "        \n",
    "        default_yield.append(weighted_yield)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.792216186596149,\n",
       " 0.7648363827925556,\n",
       " 0.779355390246026,\n",
       " 0.5899540884916881,\n",
       " 0.5184287119948298]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_yield[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 处理出错的样本\n",
    "if error_indices:\n",
    "    logger.info(f\"有 {len(error_indices)} 个样本处理出错，正在重新处理...\")\n",
    "    error_df = test_df[test_df['rxnid'].isin(error_indices)]\n",
    "    retry_results, retry_error_indices = process_samples_parallel(error_df, train_df, train_tfidf, tfidf)\n",
    "    results.update(retry_results)\n",
    "\n",
    "    if retry_error_indices:\n",
    "        logger.warning(f\"仍有 {len(retry_error_indices)} 个样本处理失败\")\n",
    "        # retry_error_idx = [int(item[4:]) - 1 for item in retry_error_indices]\n",
    "        for rxnid in retry_error_indices:\n",
    "            results[rxnid] = default_yield[int(rxnid[4:]) - 1]  # 对于始终无法处理的样本，设置一个默认值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-24 15:03:36,504 - INFO - 开始写入结果...\n",
      "2024-07-24 15:03:36,515 - INFO - 结果已保存到submit001.txt文件中\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"开始写入结果...\")\n",
    "with open('submit001.txt', 'w') as f:\n",
    "    f.write('rxnid,Yield\\n')\n",
    "    for rxnid in test_df['rxnid']:\n",
    "        yield_value = float(results.get(rxnid, default_yield[int(rxnid[4:]) - 1])) # type: ignore\n",
    "        f.write(f\"{rxnid},{yield_value:.4f}\\n\")\n",
    "logger.info(\"结果已保存到submit001.txt文件中\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理测试样本:   0%|          | 6/2616 [00:00<00:45, 57.24it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理测试样本:   3%|▎         | 71/2616 [00:01<00:44, 56.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3467 3468 3476 3477]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理测试样本:   4%|▍         | 99/2616 [00:01<00:38, 65.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[820 822 823]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理测试样本:   5%|▌         | 131/2616 [00:02<00:33, 73.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1572 8131 8132]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理测试样本:  11%|█         | 283/2616 [00:04<00:33, 68.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 574 8236 8565]\n",
      "[5652 5653 5657 5658 5659 5660]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理测试样本:  17%|█▋        | 451/2616 [00:06<00:29, 73.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  796 21313 21314]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理测试样本:  19%|█▉        | 491/2616 [00:07<00:28, 74.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  216 10202 20999 21003]\n",
      "[ 2297 13639 13640]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理测试样本:  22%|██▏       | 564/2616 [00:07<00:26, 76.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2767 2768 2772 2773 2774 2775 2777]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理测试样本:  24%|██▍       | 637/2616 [00:08<00:26, 75.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4676 4677 4678 5275 5276 5277 5278]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理测试样本:  26%|██▋       | 688/2616 [00:09<00:24, 77.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11059 11768 11769]\n",
      "[ 3307 16091 16099]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理测试样本:  27%|██▋       | 712/2616 [00:09<00:25, 74.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18266 18268 18269 18270 18271 18272 18273 18274 18275 18276 18277 18278\n",
      " 18279]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理测试样本:  35%|███▌      | 926/2616 [00:12<00:21, 77.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19427 19428 19444 19446]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理测试样本:  40%|████      | 1050/2616 [00:14<00:19, 78.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13359 13360 13361 13414 13415 13416]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理测试样本:  42%|████▏     | 1091/2616 [00:14<00:19, 77.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16393 16395 16577]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理测试样本:  43%|████▎     | 1115/2616 [00:15<00:20, 73.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14230 14232 14796]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理测试样本:  52%|█████▏    | 1360/2616 [00:18<00:17, 72.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  216  8109 10202 20999 21000 21003]\n",
      "[ 3641  3642  3852  3854  3855 16381 17063 17072 17073 17082 17083 17084]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理测试样本:  53%|█████▎    | 1384/2616 [00:19<00:17, 71.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19991 19995 19996 20010 20011]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理测试样本:  54%|█████▎    | 1400/2616 [00:19<00:16, 72.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19426 19429 19443 19445]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理测试样本:  58%|█████▊    | 1528/2616 [00:21<00:14, 73.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 9223  9224 17780 20113 20114 20115]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理测试样本:  66%|██████▌   | 1730/2616 [00:23<00:11, 75.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13537 14949 14951 16431]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理测试样本:  71%|███████▏  | 1865/2616 [00:25<00:10, 74.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11708 11709 11710]\n",
      "[ 2110 13190 13192]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理测试样本:  73%|███████▎  | 1897/2616 [00:26<00:09, 72.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18266 18268 18269 18270 18271 18272 18273 18274 18275 18276 18277 18278\n",
      " 18279]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理测试样本:  77%|███████▋  | 2003/2616 [00:27<00:07, 77.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8180 9119 9120 9121]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理测试样本:  79%|███████▉  | 2075/2616 [00:28<00:07, 75.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8368 8369 8370 8371]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理测试样本:  82%|████████▏ | 2140/2616 [00:29<00:06, 76.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7362 7363 7364]\n",
      "[ 2177  2289 12985 13383 13384 13386]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理测试样本:  85%|████████▍ | 2212/2616 [00:30<00:05, 74.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13537 13538 14948 14949 14951 14960 14962]\n",
      "[ 5982  5983 11664]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理测试样本:  86%|████████▌ | 2252/2616 [00:30<00:04, 75.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5967 5969 8737]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理测试样本:  89%|████████▉ | 2341/2616 [00:32<00:03, 73.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23528 23529 23530]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理测试样本:  90%|█████████ | 2357/2616 [00:32<00:03, 71.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2110 13190 13192]\n",
      "[22596 22598 22600 22602 22605 22606 22608]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理测试样本:  94%|█████████▍| 2455/2616 [00:33<00:02, 67.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22603 22604 22607]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理测试样本:  95%|█████████▌| 2486/2616 [00:34<00:01, 71.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  216  8109 10202 20999 21000 21003]\n",
      "[ 6703  6704 10089 21717]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理测试样本:  98%|█████████▊| 2558/2616 [00:35<00:00, 73.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21837 22277 22278]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理测试样本: 100%|██████████| 2616/2616 [00:35<00:00, 72.72it/s]\n"
     ]
    }
   ],
   "source": [
    "# 试一试：直接使用相似K个样本的均值作为预测结果\n",
    "\n",
    "# with open('submit0.txt', 'w') as f:\n",
    "#     f.write('rxnid,Yield\\n')\n",
    "#     total_samples = len(test_df)\n",
    "#     for index, test_sample in tqdm(test_df.iterrows(), total=len(test_df), desc=\"处理测试样本\"):\n",
    "#         # 对测试样本进行TF-IDF转换\n",
    "#         test_tfidf = tfidf.transform([test_sample['combined_features']])\n",
    "        \n",
    "#         # 计算与训练集的相似度\n",
    "#         similarities = cosine_similarity(test_tfidf, train_tfidf).flatten()\n",
    "        \n",
    "#         # 获取最相似的5个样本的索引\n",
    "#         top_5_indices = similarities.argsort()[-5:][::-1]\n",
    "#         # print(top_5_indices)\n",
    "#         # 获取最相似的5个样本的产率\n",
    "#         top_5_yields = train_df.iloc[top_5_indices]['Yield'].astype(float).values[0]\n",
    "#         # print(top_5_yields)\n",
    "#         # # 获取相似度权重\n",
    "#         weights = similarities[top_5_indices]\n",
    "#         # # 对权重进行归一化\n",
    "#         weights = weights / weights.sum()\n",
    "        \n",
    "#         # # 计算这五个samples的产率加权平均\n",
    "#         weighted_yield = np.dot(top_5_yields, weights) \n",
    "\n",
    "#         f.write(f\"test{index+1},{weighted_yield:.4f}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ddm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
